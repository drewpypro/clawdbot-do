services:
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "127.0.0.1:4000:4000"
    volumes:
      - ./config/litellm.yaml:/app/config.yaml:ro
    env_file: .env
    command: ["--config", "/app/config.yaml", "--port", "4000", "--host", "0.0.0.0"]
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:4000/health')\""]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  bogoyito-chat:
    build: ./openclaw
    depends_on:
      litellm:
        condition: service_healthy
    volumes:
      - ./config/chat.json:/home/clawdbot/.openclaw/config.json:ro
      - bogoyito-chat-data:/home/clawdbot/.openclaw/workspace
    env_file: .env
    environment:
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN_CHAT}
    restart: unless-stopped

volumes:
  bogoyito-chat-data:
